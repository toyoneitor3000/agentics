"""
Audio generation tools using Google Cloud AI.

Provides text-to-speech, music generation, and audio processing capabilities.
"""

import os
from pathlib import Path
from typing import Dict, Any, List

def text_to_speech(
    text: str,
    output_path: str = "./workspace/assets/audio/voiceover.mp3",
    language: str = "es-ES",
    voice_name: str = "es-ES-Neural2-A",
    speaking_rate: float = 1.0
) -> Dict[str, Any]:
    """
    Convierte texto a audio usando Google Cloud Text-to-Speech.
    
    Args:
        text: Texto a convertir en voz.
        output_path: D√≥nde guardar el archivo de audio.
        language: C√≥digo de idioma ('es-ES', 'en-US', 'pt-BR', etc.).
        voice_name: Nombre de la voz Neural2 a usar.
        speaking_rate: Velocidad de habla (0.25 a 4.0, 1.0 es normal).
        
    Returns:
        Dict con status, ruta del archivo y metadata.
    """
    try:
        project_id = os.environ.get("GOOGLE_CLOUD_PROJECT")
        
        if not project_id:
            return {
                "status": "error",
                "path": None,
                "error": "‚ùå Falta GOOGLE_CLOUD_PROJECT en .env"
            }
        
        # Import Google Cloud TTS
        try:
            from google.cloud import texttospeech
        except ImportError:
            return {
                "status": "error",
                "path": None,
                "error": "‚ùå Instala: pip install google-cloud-texttospeech"
            }
        
        # Initialize client
        client = texttospeech.TextToSpeechClient()
        
        # Build request
        synthesis_input = texttospeech.SynthesisInput(text=text)
        
        voice = texttospeech.VoiceSelectionParams(
            language_code=language,
            name=voice_name
        )
        
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=speaking_rate,
            pitch=0.0,
            volume_gain_db=0.0
        )
        
        # Generate speech
        print(f"üéôÔ∏è Generando voiceover: '{text[:50]}...'")
        print(f"üó£Ô∏è Voz: {voice_name}, Idioma: {language}")
        
        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        
        # Save audio
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_file, 'wb') as out:
            out.write(response.audio_content)
        
        return {
            "status": "success",
            "path": str(output_file.absolute()),
            "text": text[:100] + "..." if len(text) > 100 else text,
            "voice": voice_name,
            "language": language,
            "duration_estimate": len(text.split()) / 2.5,  # Rough estimate
            "message": f"‚úÖ Audio generado: {output_file}"
        }
        
    except Exception as e:
        return {
            "status": "error",
            "path": None,
            "error": f"Error generando audio: {str(e)}"
        }


def generate_music(
    prompt: str,
    output_path: str = "./background_music.wav",
    duration: int = 30,
    temperature: float = 1.0
) -> Dict[str, Any]:
    """
    Genera m√∫sica instrumental desde un prompt usando MusicLM.
    
    Args:
        prompt: Descripci√≥n del estilo musical ('upbeat electronic', 
                'calm piano jazz', 'epic orchestral', etc.).
        output_path: D√≥nde guardar el archivo de audio.
        duration: Duraci√≥n en segundos (m√°x ~30s con la versi√≥n preview).
        temperature: Creatividad (0.0-1.0, mayor = m√°s variado).
        
    Returns:
        Dict con status y ruta del audio generado.
    """
    try:
        project_id = os.environ.get("GOOGLE_CLOUD_PROJECT")
        location = os.environ.get("GOOGLE_CLOUD_LOCATION", "us-central1")
        
        if not project_id:
            return {
                "status": "error",
                "path": None,
                "error": "‚ùå Falta GOOGLE_CLOUD_PROJECT en .env"
            }
        
        # Import Vertex AI
        try:
            import vertexai
            from vertexai.preview import language_models
        except ImportError:
            return {
                "status": "error",
                "path": None,
                "error": "‚ùå Instala: pip install google-cloud-aiplatform"
            }
        
        # Note: MusicLM direct API might not be fully public yet
        # This is a placeholder for when it becomes available
        # Alternative: Use Chirp (audio generation) or wait for MusicLM API
        
        return {
            "status": "not_implemented",
            "path": None,
            "error": "üöß MusicLM API a√∫n no est√° p√∫blicamente disponible. "
                     "Usa generate_sound_effects o text_to_speech mientras tanto."
        }
        
    except Exception as e:
        return {
            "status": "error",
            "path": None,
            "error": f"Error: {str(e)}"
        }


def generate_sound_effects(
    description: str,
    output_path: str = "./sound_effect.wav",
    duration: float = 2.0
) -> Dict[str, Any]:
    """
    Genera efectos de sonido desde descripci√≥n de texto.
    
    Args:
        description: Descripci√≥n del sonido ('door closing', 'car engine', 
                     'ocean waves', etc.).
        output_path: D√≥nde guardar el archivo.
        duration: Duraci√≥n en segundos.
        
    Returns:
        Dict con status y ruta del audio.
    """
    try:
        # This would use AudioLM or similar when available
        # For now, returning placeholder
        
        return {
            "status": "not_implemented",
            "path": None,
            "error": "üöß Sound effects generation coming soon. "
                     "Usa text_to_speech para voiceovers mientras tanto."
        }
        
    except Exception as e:
        return {
            "status": "error",
            "path": None,
            "error": f"Error: {str(e)}"
        }


# Voice options reference
VOICE_OPTIONS = {
    "espa√±ol": {
        "female_casual": "es-ES-Neural2-A",
        "male_casual": "es-ES-Neural2-B",
        "female_formal": "es-ES-Neural2-C",
        "male_formal": "es-ES-Neural2-D"
    },
    "english": {
        "female_casual": "en-US-Neural2-C",
        "male_casual": "en-US-Neural2-D",
        "female_formal": "en-US-Neural2-E",
        "male_formal": "en-US-Neural2-F"
    },
    "portugu√™s": {
        "female": "pt-BR-Neural2-A",
        "male": "pt-BR-Neural2-B"
    }
}
